{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adidwiribowo/Implementasi-Arsitektur-EfficientNetV2-S-untuk-Klasifikasi-Citra-Rempah/blob/main/EfficienNetV2_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKfqvVn35rDK"
      },
      "source": [
        "# **Pip Install**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilhxoLdP69qs"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-RkZGN9Z_RW"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade jax jaxlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA3jaZbL5w98"
      },
      "source": [
        "# **Klasifikasi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9GaS0h0FF2H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nZwGqwMFuko"
      },
      "outputs": [],
      "source": [
        "# Set Path Dataset\n",
        "dataset_mentah = '/content/drive/MyDrive/Klasifikasi Rempah/New Dataset Rempah'\n",
        "dataset_baru = '/content/drive/MyDrive/Klasifikasi Rempah/EfficientNetV2/Dataset_Split'\n",
        "train_dataset = os.path.join(dataset_baru, 'train')\n",
        "val_dataset = os.path.join(dataset_baru, 'validation')\n",
        "test_dataset = '/content/drive/MyDrive/Klasifikasi Rempah/EfficientNetV2/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Tzcb_hPF5tD"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk menghitung jumlah gambar dalam setiap kelas\n",
        "def count_images_per_class(dataset_path):\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            num_images = len([img for img in os.listdir(class_path) if img.endswith(('.JPG', '.jpg', '.PNG', '.png'))])\n",
        "            class_counts[class_name] = num_images\n",
        "    return class_counts\n",
        "\n",
        "# Menampilkan jumlah gambar dalam setiap kelas sebelum split\n",
        "print(\"Jumlah gambar per kelas SEBELUM split:\")\n",
        "before_split_counts = count_images_per_class(dataset_mentah)\n",
        "for class_name, count in before_split_counts.items():\n",
        "    print(f\"{class_name}: {count} gambar\")\n",
        "\n",
        "# Stratified Dataset Split\n",
        "def stratified_split(dataset_mentah, train_dataset, val_dataset, val_size=0.3, random_seed=42):\n",
        "    for class_name in os.listdir(dataset_mentah):\n",
        "        class_path = os.path.join(dataset_mentah, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.endswith(('.JPG', '.jpg', '.PNG', '.png'))]\n",
        "            if not images:\n",
        "                print(f\"Peringatan: Tidak ada gambar di folder {class_name}\")\n",
        "                continue\n",
        "\n",
        "            # Stratified Splitting\n",
        "            train_images, val_images = train_test_split(\n",
        "                images, test_size=val_size, stratify=[class_name] * len(images), random_state=random_seed\n",
        "            )\n",
        "\n",
        "            # Copy Images ke folder train dan validation\n",
        "            for img_list, dst_dir in zip([train_images, val_images], [train_dataset, val_dataset]):\n",
        "                dst_class_dir = os.path.join(dst_dir, class_name)\n",
        "                os.makedirs(dst_class_dir, exist_ok=True)\n",
        "                for img_path in img_list:\n",
        "                    shutil.copy(img_path, dst_class_dir)\n",
        "\n",
        "# Memanggil fungsi untuk membagi data\n",
        "stratified_split(dataset_mentah, train_dataset, val_dataset)\n",
        "print(\"Splitting Dataset Selesai!\")\n",
        "\n",
        "# Menampilkan jumlah gambar dalam setiap kelas setelah split\n",
        "print(\"\\nJumlah gambar per kelas SETELAH split:\")\n",
        "print(\"\\nTraining Set:\")\n",
        "train_counts = count_images_per_class(train_dataset)\n",
        "for class_name, count in train_counts.items():\n",
        "    print(f\"{class_name}: {count} gambar\")\n",
        "\n",
        "print(\"\\nValidation Set:\")\n",
        "val_counts = count_images_per_class(val_dataset)\n",
        "for class_name, count in val_counts.items():\n",
        "    print(f\"{class_name}: {count} gambar\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menghitung jumlah gambar dalam setiap kelas\n",
        "def count_images_per_class(dataset_path):\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            num_images = len([img for img in os.listdir(class_path) if img.endswith(('.JPG', '.jpg', '.PNG', '.png'))])\n",
        "            class_counts[class_name] = num_images\n",
        "    return class_counts"
      ],
      "metadata": {
        "id": "cFOspvv0Z9G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYBDcZWPF-FP"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=[0.6, 1.3],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSlkaBwCGHjs"
      },
      "outputs": [],
      "source": [
        "# Flow Data untuk Training, Validation, dan Test\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dataset, target_size=(240, 240), batch_size=16, class_mode='categorical')\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dataset, target_size=(240, 240), batch_size=16, class_mode='categorical')\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dataset, target_size=(240, 240), batch_size=16, class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykaYYueYOB6O"
      },
      "outputs": [],
      "source": [
        "# Menampilkan beberapa gambar hasil augmentasi\n",
        "def show_augmented_images(generator, batch_size=10):\n",
        "    class_labels = list(generator.class_indices.keys())\n",
        "    images, labels = next(generator)\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for i in range(batch_size):\n",
        "        ax = plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(f\"Class: {class_labels[np.argmax(labels[i])]}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_augmented_images(train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPPMQ-SDGL7W"
      },
      "outputs": [],
      "source": [
        "# Definisikan Model EfficientNetV2S dengan Fine-Tuning\n",
        "def build_model(num_classes):\n",
        "    base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(240, 240, 3))\n",
        "    for layer in base_model.layers[:70]:\n",
        "        layer.trainable = False\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.6),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqTonwQNGlJm"
      },
      "outputs": [],
      "source": [
        "# Training Model\n",
        "num_classes = len(train_generator.class_indices)\n",
        "model = build_model(num_classes)\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
        "    TensorBoard(log_dir='./logs', histogram_freq=1)\n",
        "]\n",
        "\n",
        "\n",
        "history = model.fit(train_generator, validation_data=validation_generator, epochs=50, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5BunjLjGs1Z"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq0dCDEp6iZz"
      },
      "outputs": [],
      "source": [
        "# Evaluasi Model Menggunakan Data Uji\n",
        "results = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {results[0]:.4f}, Test Accuracy: {results[1]:.4f}, Top-3 Accuracy: {results[2]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SCwAFRym0dY"
      },
      "outputs": [],
      "source": [
        "# Prediksi pada data uji\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "# Visualisasi Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Classification Report (Precision, Recall, F1-score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyatQ29p3UVs"
      },
      "outputs": [],
      "source": [
        "# Fungsi prediksi gambar\n",
        "def predict_image(image):\n",
        "    # Preprocessing gambar\n",
        "    img = load_img(image, target_size=(240, 240))\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Prediksi dengan model\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_idx = np.argmax(predictions)\n",
        "    confidence = predictions[0][predicted_class_idx]\n",
        "    predicted_class = list(train_generator.class_indices.keys())[predicted_class_idx]\n",
        "\n",
        "    # Menentukan output berdasarkan confidence\n",
        "    if confidence < 0.5:\n",
        "        return \"INI BUKAN REMPAH SAYANG\"\n",
        "    else:\n",
        "        return f\"Predicted Class: {predicted_class} with Confidence: {confidence:.2f}\"\n",
        "\n",
        "# Membuat antarmuka Gradio\n",
        "interface = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.Image(type=\"filepath\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Spice Image Classification\",\n",
        "    description=\"Unggah gambar rempah untuk mendapatkan hasil klasifikasi.\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OKfqvVn35rDK"
      ],
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1vL94fAEeinzwfmVnWnilQ4gQLcfu-cLG",
      "authorship_tag": "ABX9TyPkguK308hGgz4ZtgqmI+Yr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}